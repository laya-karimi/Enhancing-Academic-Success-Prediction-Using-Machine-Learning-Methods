{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IzYs5kMdhuME",
        "outputId": "2cb800ff-90d3-4813-8d18-a2ea2e72fc9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "97/97 [==============================] - 1s 3ms/step - loss: 0.8161 - accuracy: 0.6625\n",
            "Epoch 2/10\n",
            "97/97 [==============================] - 0s 3ms/step - loss: 0.6565 - accuracy: 0.7361\n",
            "Epoch 3/10\n",
            "97/97 [==============================] - 0s 3ms/step - loss: 0.6047 - accuracy: 0.7552\n",
            "Epoch 4/10\n",
            "97/97 [==============================] - 0s 3ms/step - loss: 0.5819 - accuracy: 0.7632\n",
            "Epoch 5/10\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.5770 - accuracy: 0.7632\n",
            "Epoch 6/10\n",
            "97/97 [==============================] - 0s 3ms/step - loss: 0.5605 - accuracy: 0.7720\n",
            "Epoch 7/10\n",
            "97/97 [==============================] - 0s 3ms/step - loss: 0.5384 - accuracy: 0.7829\n",
            "Epoch 8/10\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.5454 - accuracy: 0.7791\n",
            "Epoch 9/10\n",
            "97/97 [==============================] - 0s 3ms/step - loss: 0.5218 - accuracy: 0.7875\n",
            "Epoch 10/10\n",
            "97/97 [==============================] - 0s 3ms/step - loss: 0.5320 - accuracy: 0.7859\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.5891 - accuracy: 0.7553\n",
            "Enhanced Deep Learning Model Accuracy: 75.53%\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Load dataset\n",
        "file_path = 'data.csv'\n",
        "df = pd.read_csv(file_path, delimiter=';')\n",
        "\n",
        "# Encoding the target variable and features\n",
        "label_encoder = LabelEncoder()\n",
        "df['Target'] = label_encoder.fit_transform(df['Target'])\n",
        "num_classes = len(df['Target'].unique())\n",
        "\n",
        "# Feature Scaling\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(df.drop('Target', axis=1))\n",
        "y_encoded = to_categorical(df['Target'])\n",
        "\n",
        "# Splitting the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_encoded, test_size=0.3, random_state=42)\n",
        "\n",
        "# Enhanced Neural Network Model\n",
        "model = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    Dropout(0.3),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Training the model\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32)\n",
        "\n",
        "# Evaluation\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Enhanced Deep Learning Model Accuracy: {accuracy * 100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PDrSfv5wwZTt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Load dataset\n",
        "file_path = 'data.csv'\n",
        "df = pd.read_csv(file_path, delimiter=';')\n",
        "\n",
        "# Encoding the target variable and features\n",
        "label_encoder = LabelEncoder()\n",
        "df['Target'] = label_encoder.fit_transform(df['Target'])\n",
        "num_classes = len(df['Target'].unique())\n",
        "\n",
        "# Feature Scaling\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(df.drop('Target', axis=1))\n",
        "y_encoded = to_categorical(df['Target'])\n",
        "\n",
        "# Splitting the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_encoded, test_size=0.3, random_state=42)\n",
        "\n",
        "# Data Augmentation for Oversampling\n",
        "# (Assuming the use of TensorFlow's data augmentation techniques if available)\n",
        "\n",
        "# Enhanced Neural Network Model\n",
        "model = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    Dropout(0.3),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Training the model on the augmented data\n",
        "model.fit(X_train, y_train, epochs=20, batch_size=32)\n",
        "\n",
        "# Evaluation\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Deep Learning Model with Oversampling Accuracy: {accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60JAFHN6yM2r",
        "outputId": "2bec9dfb-3a4a-46f5-e421-141261fa0444"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "97/97 [==============================] - 1s 3ms/step - loss: 0.7989 - accuracy: 0.6567\n",
            "Epoch 2/20\n",
            "97/97 [==============================] - 0s 3ms/step - loss: 0.6367 - accuracy: 0.7371\n",
            "Epoch 3/20\n",
            "97/97 [==============================] - 0s 3ms/step - loss: 0.6133 - accuracy: 0.7506\n",
            "Epoch 4/20\n",
            "97/97 [==============================] - 0s 3ms/step - loss: 0.5788 - accuracy: 0.7610\n",
            "Epoch 5/20\n",
            "97/97 [==============================] - 0s 3ms/step - loss: 0.5650 - accuracy: 0.7707\n",
            "Epoch 6/20\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.5505 - accuracy: 0.7797\n",
            "Epoch 7/20\n",
            "97/97 [==============================] - 0s 3ms/step - loss: 0.5377 - accuracy: 0.7829\n",
            "Epoch 8/20\n",
            "97/97 [==============================] - 0s 3ms/step - loss: 0.5410 - accuracy: 0.7765\n",
            "Epoch 9/20\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.5324 - accuracy: 0.7813\n",
            "Epoch 10/20\n",
            "97/97 [==============================] - 0s 3ms/step - loss: 0.5288 - accuracy: 0.7826\n",
            "Epoch 11/20\n",
            "97/97 [==============================] - 0s 3ms/step - loss: 0.5192 - accuracy: 0.7875\n",
            "Epoch 12/20\n",
            "97/97 [==============================] - 0s 3ms/step - loss: 0.5125 - accuracy: 0.7968\n",
            "Epoch 13/20\n",
            "97/97 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7904\n",
            "Epoch 14/20\n",
            "97/97 [==============================] - 0s 3ms/step - loss: 0.4994 - accuracy: 0.7946\n",
            "Epoch 15/20\n",
            "97/97 [==============================] - 0s 3ms/step - loss: 0.4895 - accuracy: 0.8043\n",
            "Epoch 16/20\n",
            "97/97 [==============================] - 0s 3ms/step - loss: 0.4793 - accuracy: 0.8117\n",
            "Epoch 17/20\n",
            "97/97 [==============================] - 0s 3ms/step - loss: 0.4785 - accuracy: 0.8049\n",
            "Epoch 18/20\n",
            "97/97 [==============================] - 0s 3ms/step - loss: 0.4756 - accuracy: 0.8033\n",
            "Epoch 19/20\n",
            "97/97 [==============================] - 0s 3ms/step - loss: 0.4652 - accuracy: 0.8136\n",
            "Epoch 20/20\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.4724 - accuracy: 0.8104\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.6037 - accuracy: 0.7658\n",
            "Deep Learning Model with Oversampling Accuracy: 76.58%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oIiwUomZyNai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Load dataset\n",
        "file_path = 'data.csv'\n",
        "df = pd.read_csv(file_path, delimiter=';')\n",
        "\n",
        "# Encoding the target variable\n",
        "label_encoder = LabelEncoder()\n",
        "df['Target'] = label_encoder.fit_transform(df['Target'])\n",
        "num_classes = len(df['Target'].unique())\n",
        "\n",
        "# Undersampling\n",
        "class_counts = df['Target'].value_counts()\n",
        "min_class_size = class_counts.min()\n",
        "\n",
        "df_undersampled = pd.concat([\n",
        "    df[df['Target'] == cls].sample(min_class_size, random_state=42) for cls in class_counts.index\n",
        "])\n",
        "\n",
        "# Splitting the dataset into features and target variable\n",
        "X = df_undersampled.drop('Target', axis=1)\n",
        "y = to_categorical(df_undersampled['Target'])\n",
        "\n",
        "# Feature Scaling\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Splitting the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Neural Network Model\n",
        "model = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    Dropout(0.3),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Training the model\n",
        "model.fit(X_train, y_train, epochs=20, batch_size=32)\n",
        "\n",
        "# Evaluation\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Deep Learning Model with Undersampling Accuracy: {accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJKSyN6ZyYY3",
        "outputId": "c5f799ab-9d9c-4dfc-cd40-ab1efa5b51f0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "53/53 [==============================] - 1s 3ms/step - loss: 0.9994 - accuracy: 0.5069\n",
            "Epoch 2/20\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.8235 - accuracy: 0.6419\n",
            "Epoch 3/20\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.7743 - accuracy: 0.6677\n",
            "Epoch 4/20\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.7397 - accuracy: 0.6815\n",
            "Epoch 5/20\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6998 - accuracy: 0.7115\n",
            "Epoch 6/20\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6984 - accuracy: 0.7025\n",
            "Epoch 7/20\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6726 - accuracy: 0.7043\n",
            "Epoch 8/20\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6523 - accuracy: 0.7169\n",
            "Epoch 9/20\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6628 - accuracy: 0.7259\n",
            "Epoch 10/20\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6416 - accuracy: 0.7181\n",
            "Epoch 11/20\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6408 - accuracy: 0.7175\n",
            "Epoch 12/20\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6240 - accuracy: 0.7307\n",
            "Epoch 13/20\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6123 - accuracy: 0.7361\n",
            "Epoch 14/20\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.6078 - accuracy: 0.7397\n",
            "Epoch 15/20\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6034 - accuracy: 0.7409\n",
            "Epoch 16/20\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.6028 - accuracy: 0.7331\n",
            "Epoch 17/20\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.5925 - accuracy: 0.7504\n",
            "Epoch 18/20\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.5755 - accuracy: 0.7540\n",
            "Epoch 19/20\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.5689 - accuracy: 0.7540\n",
            "Epoch 20/20\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.5856 - accuracy: 0.7534\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.6740 - accuracy: 0.7147\n",
            "Deep Learning Model with Undersampling Accuracy: 71.47%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "INDwRUQ2yi80"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}