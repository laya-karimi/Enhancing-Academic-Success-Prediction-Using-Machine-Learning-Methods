{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_M2H0PEBnKuJ",
        "outputId": "8a7eba8a-8c1b-4b0e-f4ac-db3528fb7c88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n",
            "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
            "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
            "Ensemble Model Accuracy: 73.64%\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('data.csv', delimiter=';')\n",
        "\n",
        "# Data Preprocessing\n",
        "# Assuming the preprocessing is needed based on the dataset structure\n",
        "# Handle missing values, encode categorical variables if any\n",
        "\n",
        "# Encode target variable\n",
        "label_encoder = LabelEncoder()\n",
        "df['Target'] = label_encoder.fit_transform(df['Target'])\n",
        "\n",
        "# Feature Engineering\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(df.drop('Target', axis=1))\n",
        "\n",
        "pca = PCA(n_components=0.95)  # Retain 95% variance\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "# Splitting the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_pca, df['Target'], test_size=0.3, random_state=42)\n",
        "\n",
        "# Apply SMOTE\n",
        "smote = SMOTE()\n",
        "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Model Training and Hyperparameter Tuning\n",
        "# Random Forest\n",
        "rf_params = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'max_depth': [10, 20, None],\n",
        "    'min_samples_split': [2, 5],\n",
        "    'min_samples_leaf': [1, 2],\n",
        "    'bootstrap': [True, False]\n",
        "}\n",
        "rf = RandomForestClassifier()\n",
        "rf_grid = GridSearchCV(estimator=rf, param_grid=rf_params, cv=3, n_jobs=-1, verbose=2, scoring='accuracy')\n",
        "rf_grid.fit(X_train_smote, y_train_smote)\n",
        "rf_best = rf_grid.best_estimator_\n",
        "\n",
        "# XGBoost\n",
        "xgb_params = {\n",
        "    'max_depth': [3, 5],\n",
        "    'learning_rate': [0.01, 0.1],\n",
        "    'n_estimators': [100, 200],\n",
        "    'subsample': [0.7, 0.9]\n",
        "}\n",
        "xgb = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
        "xgb_grid = GridSearchCV(estimator=xgb, param_grid=xgb_params, cv=3, n_jobs=-1, verbose=2, scoring='accuracy')\n",
        "xgb_grid.fit(X_train_smote, y_train_smote)\n",
        "xgb_best = xgb_grid.best_estimator_\n",
        "\n",
        "# SVM\n",
        "svm_params = {\n",
        "    'C': [1, 10],\n",
        "    'gamma': [0.001, 0.01]\n",
        "}\n",
        "svm = SVC(probability=True)\n",
        "svm_grid = GridSearchCV(estimator=svm, param_grid=svm_params, cv=3, n_jobs=-1, verbose=2, scoring='accuracy')\n",
        "svm_grid.fit(X_train_smote, y_train_smote)\n",
        "svm_best = svm_grid.best_estimator_\n",
        "\n",
        "# Ensemble Method - Voting Classifier\n",
        "voting_clf = VotingClassifier(\n",
        "    estimators=[('rf', rf_best), ('xgb', xgb_best), ('svm', svm_best)],\n",
        "    voting='soft'\n",
        ")\n",
        "voting_clf.fit(X_train_smote, y_train_smote)\n",
        "\n",
        "# Evaluation\n",
        "y_pred = voting_clf.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Ensemble Model Accuracy: %.2f%%\" % (accuracy * 100.0))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QtEr7vINrRmN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nRgYqc5MvCIA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('data.csv', delimiter=';')\n",
        "\n",
        "# Basic Data Preprocessing\n",
        "# Handle missing values (if any) and encode categorical variables\n",
        "\n",
        "# Encoding the target variable\n",
        "label_encoder = LabelEncoder()\n",
        "df['Target'] = label_encoder.fit_transform(df['Target'])\n",
        "\n",
        "# Feature Scaling\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(df.drop('Target', axis=1))\n",
        "\n",
        "# Splitting the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, df['Target'], test_size=0.3, random_state=42)\n",
        "\n",
        "# Balancing Classes with SMOTE\n",
        "smote = SMOTE()\n",
        "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Random Forest Model with Basic Hyperparameter Tuning\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 150, 200],\n",
        "    'max_depth': [10, 15, 20],\n",
        "    'min_samples_split': [2, 4],\n",
        "    'min_samples_leaf': [1, 2]\n",
        "}\n",
        "\n",
        "rf = RandomForestClassifier()\n",
        "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2, scoring='accuracy')\n",
        "grid_search.fit(X_train_smote, y_train_smote)\n",
        "best_rf = grid_search.best_estimator_\n",
        "\n",
        "# Evaluation\n",
        "y_pred = best_rf.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Simplified Random Forest Accuracy: %.2f%%\" % (accuracy * 100.0))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMrvg8iyvCcU",
        "outputId": "58cee2c8-7cf2-472e-bb9a-9a5d4e365cac"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n",
            "Simplified Random Forest Accuracy: 77.03%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "257Gi0H-vDEB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}